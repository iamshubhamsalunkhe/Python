dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
# This data set consists of expression measurements for 2,308 genes. The training and test sets consist
# of 63 and 20 observations respectively.
table(Khan$ytrain)
table(Khan$ytest)
# We will use a support vector approach to predict cancer subtype using gene expression measurements.
# In this data set, there are a very large number of features relative to the number of observations.
# This suggests that we should use a linear kernel, because the additional ???exibility that will result
# from using a polynomial or radial kernel is unnecessary.
dat=data.frame(x=Khan$xtrain, y=as.factor(Khan$ytrain))
out=svm(y~., data=dat, kernel="linear",cost=10)
summary(out)
table(out$fitted, dat$y)
# We see that there are no training errors. In fact, this is not surprising, because the large number
# of variables relative to the number of observations implies that it is easy to ???nd hyperplanes that
# fully separate the classes. We are most interested not in the support vector classi???er's performance
# on the training observations, but rather its performance on the test observations.
dat.te=data.frame(x=Khan$xtest, y=as.factor(Khan$ytest))
pred.te=predict(out, newdata=dat.te)
table(pred.te, dat.te$y)
# We see that using cost=10 yields two test set errors on this data.
rm(list=ls())
library(tree)
data  <- read.csv(file.choose())
rm(list=ls())
library(tree)
data  <- read.csv(file.choose())
head(data)
summary(data)
View(data)
data$householdincome <- data$ApplicantIncome + data$CoapplicantIncome
colnames(data)
data <- data[ ,-c(1,7,8)]
summary(data)
data <- na.omit(data)
data$Dependents <- ifelse((data$Dependents == 0), 0, 1)
colSums(is.na(data))
data$Dependents <- as.factor(data$Dependents)
data$Credit_History <- as.factor(data$Credit_History)
data$LoanAmount <- as.numeric(data$LoanAmount)
data$Loan_Amount_Term <- as.numeric(data$Loan_Amount_Term)
library(tree)
tree.data <- tree(data$Loan_Status ~ . , data = data)
plot(tree.data)
text(tree.data , pretty = 0)
tree.pred = predict(tree.data , data ,type = "class" )
table(tree.pred , data$Loan_Status)
accuracy <- mean(tree.pred == data$Loan_Status)
accuracy
misclassfiacation  <- mean(tree.pred != data$Loan_Status)
misclassfiacation
#################################33
set.seed(2)
test <- read.csv(file.choose())
head(test)
test$householdincome <- test$ApplicantIncome + test$CoapplicantIncome
colnames(test)
test <- test[ ,-c(1,7,8)]
summary(test)
test <- na.omit(test)
test$Dependents <- ifelse((test$Dependents == 0), 0, 1)
str(test)
colSums(is.na(test))
test$Dependents <- as.factor(test$Dependents)
test$Credit_History <- as.factor(test$Credit_History)
test$LoanAmount <- as.numeric(test$LoanAmount)
test$Loan_Amount_Term <- as.numeric(test$Loan_Amount_Term)
test <- test[,c(test$Gender , test$Married ,test$Dependents,test$Education ,
test$Self_Employed ,test$LoanAmount ,test$Loan_Amount_Term ,
test$Credit_History ,test$Property_Area ,test$householdincome,
test$loanstatus)]
head(test)
test.pred <- predict(tree.data ,test = "class")
table(test.pred,test.loan)
rm(list=ls())
library(tree)
data  <- read.csv(file.choose())
head(data)
summary(data)
View(data)
data$householdincome <- data$ApplicantIncome + data$CoapplicantIncome
colnames(data)
data <- data[ ,-c(1,7,8)]
summary(data)
data <- na.omit(data)
data$Dependents <- ifelse((data$Dependents == 0), 0, 1)
colSums(is.na(data))
data$Dependents <- as.factor(data$Dependents)
data$Credit_History <- as.factor(data$Credit_History)
data$LoanAmount <- as.numeric(data$LoanAmount)
data$Loan_Amount_Term <- as.numeric(data$Loan_Amount_Term)
library(tree)
tree.data <- tree(data$Loan_Status ~ . , data = data)
plot(tree.data)
text(tree.data , pretty = 0)
tree.pred = predict(tree.data , data ,type = "class" )
table(tree.pred , data$Loan_Status)
accuracy <- mean(tree.pred == data$Loan_Status)
accuracy
misclassfiacation  <- mean(tree.pred != data$Loan_Status)
misclassfiacation
set.seed(2)
test <- read.csv(file.choose())
head(test)
test$householdincome <- test$ApplicantIncome + test$CoapplicantIncome
colnames(test)
test <- test[ ,-c(1,7,8)]
summary(test)
test <- na.omit(test)
test$Dependents <- ifelse((test$Dependents == 0), 0, 1)
str(test)
colSums(is.na(test))
test$Dependents <- as.factor(test$Dependents)
test$Credit_History <- as.factor(test$Credit_History)
test$LoanAmount <- as.numeric(test$LoanAmount)
test$Loan_Amount_Term <- as.numeric(test$Loan_Amount_Term)
x=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
y=c(3,4,5,4,8,10,10,11,14,20,23,24,32,34,35,37,42,48,53,60)
#Create a data frame of the data
train=data.frame(x,y)
#Plot the dataset
plot(train,pch=16)
model <- lm(y ~ x, train)
#Plot the model using abline
abline(model)
#SVM
library(e1071)
#Fit a model. The function syntax is very similar to lm function
model_svm <- svm(y ~ x , train)
#Use the predictions on the data
pred <- predict(model_svm, train)
#Plot the predictions and the plot to see our model fit
points(train$x, pred, col = "blue", pch=4)
#Linear model has a residuals part which we can extract and directly calculate rmse
error <- model$residuals
lm_error <- sqrt(mean(error^2)) # 3.832974
lm_error
error_2 <- train$y - pred
svm_error <- sqrt(mean(error_2^2)) # 2.696281
svm_error
svm_tune <- tune(svm, y ~ x, data = train,
ranges = list(epsilon = seq(0,1,0.01), cost = 2^(2:9)))
print(svm_tune)
#The best model
best_mod <- svm_tune$best.model
best_mod_pred <- predict(best_mod, train)
error_best_mod <- train$y - best_mod_pred
best_mod_RMSE <- sqrt(mean(error_best_mod^2)) # 1.290738
best_mod_RMSE
plot(svm_tune)
plot(train,pch=16)
points(train$x, best_mod_pred, col = "blue", pch=4)
length(seq(0,1,0.01))
length(2^(2:9))
rm(list = ls())
library(e1071)
set.seed(1)
x=matrix(rnorm(200*2), ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
y=c(rep(1,150),rep(2,50))
dat=data.frame(x=x,y=as.factor(y))
plot(x, col=y)
train=sample(200,100)
svmfit=svm(y~., data=dat[train,], kernel="radial",  gamma=1, cost=1)
plot(svmfit, dat[train,])
rm(list = ls())
data <- read.csv(file.choose())
head(data)
data$Household_income <- data$ApplicantIncome + data$CoapplicantIncome
head(data$Household_income)
data$Dependents <- ifelse(data$Dependents == 1 , 0,1)
head(data$Dependents)
data$Dependents <- ifelse(data$Dependents == 0 , 0,1)
head(data$Dependents)
data <- read.csv(file.choose())
head(data)
data$Household_income <- data$ApplicantIncome + data$CoapplicantIncome
head(data$Household_income)
head(data$Dependents)
colSums(is.na(data))
data <- datanb
data <- datanb
data <- na.omit(data)
colSums(is.na(data))
head(data$Dependents)
data$Dependents <- ifelse(data$Dependents == 0 , 0,1)
head(data$Dependents)
dim(data)
set.seed(1)
data <- train[1:400,]
train <- data[1:400,]
test <- data[-train,]
test <- data [-train,]
test <- data [401:529,]
colnames(train)
str(data)
data$Dependents <- as.factor(data$Dependents)
data$LoanAmount <- as.numeric(data$LoanAmount)
data$Loan_Amount_Term <- as.numeric(data$Loan_Amount_Term)
View(data)
data$Property_Area <- ifelse(data$Property_Area == "Rural" , 0,
ifelse(data$Property_Area == "Urban" , 1 , 2))
View(data)
dim(data)
set.seed(1)
train <- data[1:400,]
test <- data [401:529,]
colnames(train)
train <- -c[,1,7,8]
train <- -c(data$Loan_ID,data$ApplicantIncome , data$CoapplicantIncome)
colnames(train)
train <- data[1:400,]
test <- data [401:529,]
colnames(train)
train$Loan_ID <- NULL
colnames(train)
train$ApplicantIncome <- NULL
train$CoapplicantIncome <- NULL
colnames(train)
library(e1071)
data_model <- naiveBayes(train$Loan_Status ~ ., data = train)
summary(data_model)
data_model
model_pred <- predict(data_model ,test)
table(model_pred , test$Loan_Status)
22+86/22+5+16+86
(22+86)/22+5+16+86
22+5+16+86
(22+86)/129
library(mlr)
task = makeClassifTask(data = test , target = "Loan_Status")
task
selected_model = makeLearner("classif.naiveBayes")
selected_model
#train the model
NB_mlr = train(selected_model , task)
NB_mlr
# The summary of the model which was printed in e3071 package is stored in
# learner model. Let's print it and compare
NB_mlr$learner.model
test$Loan_ID <- NULL
test$ApplicantIncome <- NULL
test$CoapplicantIncome <- NULL
colnames(test)
data_model <- naiveBayes(train$Loan_Status ~ ., data = train)
data_model
model_pred <- predict(data_model ,test)
table(model_pred , test$Loan_Status)
(22+86)/129
library(mlr)
task = makeClassifTask(data = test , target = "Loan_Status")
task
selected_model = makeLearner("classif.naiveBayes")
selected_model
#train the model
NB_mlr = train(selected_model , task)
NB_mlr
NB_mlr$learner.model
colnames(test)
NBmlr_pred <- as.data.frame(predict(NB_mlr , newdata = test[,-10]))
summary(NBmlr_pred)
table(NBmlr_pred ,test$Loan_Status)
table(NBmlr_pred [,1],test$Loan_Status)
22+3+88+15
(22+88)/128
selected_model <- makeLearner("classif.naiveBayes",
predict.threshold = 0.6,
predict.type = 'prob')
selected_model
NB_mlr <- train(selected_model,task)
NB_mlr
NB_mlr$learner.model
NBmlr_pred <- as.data.frame(predict(NB_mlr ,newdata = test[,-10]))
summary(NBmlr_pred)
head(NBmlr_pred)
table(NBmlr_pred[,3],test$Loan_Status)
23+3+15+88
(23+88)/129
table(NBmlr_pred[,1],test$Loan_Status)
table(NBmlr_pred[,3],test$Loan_Status)
23+3+15+88
(23+88)/129
rm(list = ls())
data <- read.csv(file.choose())
head(data)
str(data)
data$Dependents <- as.factor(data$Dependents)
data$LoanAmount <- as.numeric(data$LoanAmount)
data$Loan_Amount_Term <- as.numeric(data$Loan_Amount_Term)
data$Household_income <- data$ApplicantIncome + data$CoapplicantIncome
head(data$Household_income)
colSums(is.na(data))
data <- na.omit(data)
data$Dependents <- ifelse(data$Dependents == 0 , 0,1)
head(data$Dependents)
data$Property_Area <- ifelse(data$Property_Area == "Rural" , 0,
ifelse(data$Property_Area == "Urban" , 1 , 2))
View(data)
dim(data)
set.seed(1)
train <- data[1:400,]
test <- data [401:529,]
colnames(train)
train$Loan_ID <- NULL
train$ApplicantIncome <- NULL
train$CoapplicantIncome <- NULL
test$Loan_ID <- NULL
test$ApplicantIncome <- NULL
test$CoapplicantIncome <- NULL
colnames(train)
colnames(test)
glm.fits <- glm(train$Loan_Status ~ ., data = train , family = binomial)
summary(glm.fits)
coef(glm.fits)
summary(glm.fits)$coef
summary(glm.fits)$coef[,4]
glm.prob <- predict(glm.fits , type = "response")
glm.prob[1:10]
contrasts(Direction)
contrasts(train$Loan_Status)
dim(train)
glm.pred <- rep("NO" , 400)
glm.pred[glm.prob > .6] = yes
glm.pred[glm.prob > .6]="YES"
round(glm.prob[1:10], 2)
glm.pred[1:10]
glm.pred[1:20]
round(glm.prob[1:20], 2)
glm.pred[1:20]
glm.prob <- predict(glm.fits ,newdata = test, type = "response")
glm.prob[1:10]
contrasts(train$Loan_Status)
contrasts(test$Loan_Status)
dim(test)
##this comman creates a vector where all elements are no in glm.pred
glm.pred <- rep("NO" , 129)
# this code gives yes to probabilities of glm.prob greater than 0.6 in glm .pred
glm.pred[glm.prob > .6]="YES"
round(glm.prob[1:20], 2)
glm.pred[1:20]
table(glm.fits , test)
table(glm.fits , glm.pred)
table(glm.pred , test$Loan_Status)
mean(glm.pred==test$Loan_Status)
mode(glm.pred==test$Loan_Status)
#glm.pred  N  Y
#NO  25 12
#YES 13 79
25+12+13+79
(25+79)/129
(25+79)/129
#0.8062016
library(MASS)
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)/2)
ncol(Boston)
library(randomForest)
set.seed(1)
bag.boston=randomForest(medv~., data=Boston, subset=train,
mtry=13, importance=TRUE)
bag.boston
yhat.bag = predict(bag.boston, newdata=Boston[-train, ])
boston.test=Boston[-train, "medv"]
mean((yhat.bag-boston.test)^2)
bag.boston=randomForest(medv~., data=Boston, subset=train,
mtry=13, ntree=25)
yhat.bag = predict(bag.boston, newdata=Boston[-train, ])
mean((yhat.bag-boston.test)^2)
rf.boston=randomForest(medv~., data=Boston, subset=train,
mtry=6, importance=TRUE)
yhat.rf = predict(rf.boston, newdata=Boston[-train, ])
mean((yhat.rf-boston.test)^2)
importance(rf.boston)
varImpPlot(rf.boston)
set.seed(1)
x=matrix(rnorm(200*2), ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150,]=x[101:150,]-2
y=c(rep(1,150),rep(2,50))
dat=data.frame(x=x,y=as.factor(y))
plot(x, col=y)
train=sample(200,100)
svmfit=svm(y~., data=dat[train,], kernel="radial",  gamma=1, cost=1)
library(e1071)
svmfit=svm(y~., data=dat[train,], kernel="radial",  gamma=1, cost=1)
plot(svmfit, dat[train,])
summary(svmfit)
svmfit1=svm(y~., data=dat[train,], kernel="radial",gamma=1,cost=1e5)
plot(svmfit1,dat[train,])
set.seed(1)
tune.out=tune(svm, y~., data=dat[train,], kernel="radial", ranges=list(cost=c(0.1,1,10,100,1000),
gamma=c(0.5,1,2,3,4)))
summary(tune.out) #check lowest error
tune.out$best.model
table(true=dat[-train,"y"], pred=predict(tune.out$best.model,newdata=dat[-train,]))
library(e1071)
library(ISLR)
?Khan
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
table(Khan$ytrain)
table(Khan$ytest)
########
rm(list=ls())
train <- read.csv(file.choose())
test <- read.csv(file.choose())
complete_data <- rbind(train,test)
summary(complete_data)
colSums(is.na(complete_data))
library(corrplot)
str(complete_data)
colnames(complete_data)
library(randomForest)
set.seed(1)
dim(complete_data)
rf_data <- randomForest(train$class ~ -train$duration . , data = complete_data , subset = train,
mtry = 41 ,importance = TRUE)
rf_data <- randomForest(train$class ~ . -train$duration  , data = complete_data , subset = train,
mtry = 41 ,importance = TRUE)
rf_data <- randomForest(class ~ . duration  , data = complete_data , subset = train,
mtry = 41 ,importance = TRUE)
rf_data <- randomForest(class ~ . - duration  , data = complete_data , subset = train,
mtry = 41, importance = TRUE)
range(complete_data$duration)
rf_data <- randomForest(class ~ . - duration  , data = train,
mtry = 41, importance = TRUE)
summary(train)
rf_data <- randomForest(class ~ . - duration  , data = train,
mtry = 41, importance = TRUE)
##fitting a svm mode
svm_tune <- tune(svm, train1$Class ~ ., data = train1,ranges = list(epsilon = seq(0,1,0.01), cost = 2^(2:9)))
## svm practise
##credit card fraud dataset from kaggle
##goal is to classify fraudulent transaction
##load the dataset file
library(e1071)
rm(list=ls())
############
?Auto
############
library(ISLR)
?Auto
scatterplotmatrix <- scatterplot(Auto)
cor(Auto[,1:9])
pairs(Auto)
pairs(Auto)
############
library(ISLR)
?Auto
pairs(Auto)
rm(list = ls())
Aptitute = read.csv("Project 1_Dataset.csv")
setwd("~/Rcodes/R datasets")
Aptitute = read.csv("Project 1_Dataset.csv")
# Data snapshot
View(Aptitute)
Aptitute$rank = as.factor(Aptitute$rank)
AptGLM = glm(admit~.,Aptitute,family="binomial")
summary(AptGLM)
AptGLM = glm(admit~gre+gpa+rank,Aptitute,family="binomial")
summary(AptGLM)
Predictions = predict(AptGLM, Aptitute, type="response")
Predictions
Predicted_Aptitute = cbind(Aptitute, Predictions)
head(Predicted_Aptitute)
Predicted_Aptitute_Categorized = transform(Predicted_Aptitute,
Predicted_Admission = ifelse(Predictions<.5,0,1))
head(Predicted_Aptitute_Categorized)
log_accuracy = mean(Predicted_Aptitute_Categorized$admit == Predicted_Aptitute_Categorized$Predicted_Admission)
log_accuracy
library(tree)
tree_Apt = tree(admit ~ . , Aptitute)
Predictions = predict(tree_Apt, Aptitute)
Predictions
Predicted_Aptitute = cbind(Aptitute,Predictions)
head(Predicted_Aptitute)
Predicted_Aptitute_Categorized = transform(Predicted_Aptitute,
Predicted_Admission = ifelse(Predictions<.5,0,1))
head(Predicted_Aptitute_Categorized)
dt_accuracy = mean(Predicted_Aptitute_Categorized$admit == Predicted_Aptitute_Categorized$Predicted_Admission)
dt_accuracy
## Random Forest
dim(Aptitute)
class(Aptitute$admit)
Aptitute$admit = as.factor(Aptitute$admit)
tree_Apt = randomForest(admit ~ . , Aptitute, mtry = sqrt(7), importance=TRUE)
tree_Apt = randomForest(admit ~ . , Aptitute, mtry = sqrt(7), importance=TRUE)
## Random Forest
dim(Aptitute)
class(Aptitute$admit)
Aptitute$admit = as.factor(Aptitute$admit)
tree_Apt = randomForest(admit ~ . , Aptitute, mtry = sqrt(7), importance=TRUE)
## Random Forest
library(randomForest)
dim(Aptitute)
class(Aptitute$admit)
Aptitute$admit = as.factor(Aptitute$admit)
tree_Apt = randomForest(admit ~ . , Aptitute, mtry = sqrt(7), importance=TRUE)
Predictions = predict(tree_Apt, Aptitute, type = "response")
Predictions
rf_accuracy = mean(Aptitute$admit == Predictions)
rf_accuracy
models_ = c('log_accuracy', 'dt_accuracy', 'rf_accuracy')
accuracy_ = c(log_accuracy, dt_accuracy, rf_accuracy)
tbl = cbind(models_, accuracy_)
tbl
