{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import health data\n",
    "healthdata = pd.read_csv('Health.csv') #can putm path of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ethnicity  Height (CM)  Weight (Kg) Will survive till 70\n",
      "0     White        186.0         90.0                  Yes\n",
      "1   African        185.0         98.0                   No\n",
      "2     Asian        175.0         80.0                   No\n",
      "3     White        180.0         88.0                  Yes\n",
      "4     Asian        178.0          NaN                   No\n",
      "5     Asian        172.0         72.0                  Yes\n",
      "6   African        178.0         75.0                   No\n",
      "7     White          NaN         89.0                  Yes\n",
      "8   African        186.0         90.0                  Yes\n"
     ]
    }
   ],
   "source": [
    "print(healthdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = healthdata.iloc [:,:-1].values # features and\n",
    "y = healthdata.iloc[:,3].values # y target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['White' 186.0 90.0]\n",
      " ['African' 185.0 98.0]\n",
      " ['Asian' 175.0 80.0]\n",
      " ['White' 180.0 88.0]\n",
      " ['Asian' 178.0 nan]\n",
      " ['Asian' 172.0 72.0]\n",
      " ['African' 178.0 75.0]\n",
      " ['White' nan 89.0]\n",
      " ['African' 186.0 90.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'No' 'Yes' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\Anaconda3.1\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "missingValueImputer = Imputer(missing_values = 'NaN',strategy = 'mean', axis = 0 )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "missingValueImputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[186.0, 90.0],\n",
       "       [185.0, 98.0],\n",
       "       [175.0, 80.0],\n",
       "       [180.0, 88.0],\n",
       "       [178.0, nan],\n",
       "       [172.0, 72.0],\n",
       "       [178.0, 75.0],\n",
       "       [nan, 89.0],\n",
       "       [186.0, 90.0]], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingValueImputer = missingValueImputer.fit(x[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[186.0, 90.0],\n",
       "       [185.0, 98.0],\n",
       "       [175.0, 80.0],\n",
       "       [180.0, 88.0],\n",
       "       [178.0, nan],\n",
       "       [172.0, 72.0],\n",
       "       [178.0, 75.0],\n",
       "       [nan, 89.0],\n",
       "       [186.0, 90.0]], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,1:3] = missingValueImputer.transform(x[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[186.0, 90.0],\n",
       "       [185.0, 98.0],\n",
       "       [175.0, 80.0],\n",
       "       [180.0, 88.0],\n",
       "       [178.0, 85.25],\n",
       "       [172.0, 72.0],\n",
       "       [178.0, 75.0],\n",
       "       [180.0, 89.0],\n",
       "       [186.0, 90.0]], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['White' 'African' 'Asian' 'White' 'Asian' 'Asian' 'African' 'White'\n",
      " 'African']\n",
      "[2 0 1 2 1 1 0 2 0]\n",
      "['Yes' 'No' 'No' 'Yes' 'No' 'Yes' 'No' 'Yes' 'Yes']\n",
      "[1 0 0 1 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_labelencoder = LabelEncoder()\n",
    "\n",
    "print(x[:,0])\n",
    "x[:,0] = X_labelencoder.fit_transform(x[:,0])\n",
    "print(x[:,0])\n",
    "\n",
    "#for y\n",
    "\n",
    "\n",
    "y_labelencoder = LabelEncoder()\n",
    "\n",
    "\n",
    "print(y)\n",
    "\n",
    "\n",
    "y=y_labelencoder.fit_transform(y)\n",
    "\n",
    "\n",
    "\n",
    "print(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 186.0 90.0]\n",
      " [0 185.0 98.0]\n",
      " [1 175.0 80.0]\n",
      " [2 180.0 88.0]\n",
      " [1 178.0 85.25]\n",
      " [1 172.0 72.0]\n",
      " [0 178.0 75.0]\n",
      " [2 180.0 89.0]\n",
      " [0 186.0 90.0]]\n",
      "[[  0.     0.     1.   186.    90.  ]\n",
      " [  1.     0.     0.   185.    98.  ]\n",
      " [  0.     1.     0.   175.    80.  ]\n",
      " [  0.     0.     1.   180.    88.  ]\n",
      " [  0.     1.     0.   178.    85.25]\n",
      " [  0.     1.     0.   172.    72.  ]\n",
      " [  1.     0.     0.   178.    75.  ]\n",
      " [  0.     0.     1.   180.    89.  ]\n",
      " [  1.     0.     0.   186.    90.  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\Anaconda3.1\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Shubham\\Anaconda3.1\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "\n",
    "X_onehotencoder = OneHotEncoder (categorical_features = [0])\n",
    "print(x)\n",
    "\n",
    "x = X_onehotencoder.fit_transform(x).toarray()\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test =train_test_split(x,y,test_size = 0.2 ,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.     0.     0.   185.    98.  ]\n",
      " [  0.     1.     0.   178.    85.25]\n",
      " [  1.     0.     0.   186.    90.  ]\n",
      " [  1.     0.     0.   178.    75.  ]\n",
      " [  0.     0.     1.   180.    88.  ]\n",
      " [  0.     0.     1.   186.    90.  ]\n",
      " [  0.     1.     0.   172.    72.  ]]\n",
      "[0 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[185.    98.  ]\n",
      " [178.    85.25]\n",
      " [186.    90.  ]\n",
      " [178.    75.  ]\n",
      " [180.    88.  ]\n",
      " [186.    90.  ]\n",
      " [172.    72.  ]]\n",
      "[[185.    98.  ]\n",
      " [178.    85.25]\n",
      " [186.    90.  ]\n",
      " [178.    75.  ]\n",
      " [180.    88.  ]\n",
      " [186.    90.  ]\n",
      " [172.    72.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:,3:])\n",
    "X_train1 = X_train[:,3:]\n",
    "\n",
    "print(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   1. 180.  89.]\n",
      " [  0.   1.   0. 175.  80.]]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[180.  89.]\n",
      " [175.  80.]]\n",
      "[[180.  89.]\n",
      " [175.  80.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[:,3:])\n",
    "X_test1=X_test[:,3:]\n",
    "print(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScalar\n",
    "independent_scalar = StandardScalar()\n",
    "X_train_std = independent_scalar.fit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.     0.     0.   185.    98.  ]\n",
      " [  0.     1.     0.   178.    85.25]\n",
      " [  1.     0.     0.   186.    90.  ]\n",
      " [  1.     0.     0.   178.    75.  ]\n",
      " [  0.     0.     1.   180.    88.  ]\n",
      " [  0.     0.     1.   186.    90.  ]\n",
      " [  0.     1.     0.   172.    72.  ]]\n",
      "[[1.         0.         0.         0.92857143 1.        ]\n",
      " [0.         1.         0.         0.42857143 0.50961538]\n",
      " [1.         0.         0.         1.         0.69230769]\n",
      " [1.         0.         0.         0.42857143 0.11538462]\n",
      " [0.         0.         1.         0.57142857 0.61538462]\n",
      " [0.         0.         1.         1.         0.69230769]\n",
      " [0.         1.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing  import MinMaxScaler\n",
    "nms = MinMaxScaler()\n",
    "\n",
    "X_train_norm = nms.fit_transform(X_train)\n",
    "X__test_norm = nms.fit_transform(X_test)\n",
    "\n",
    "print(X_train)\n",
    "print(X_train_norm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
